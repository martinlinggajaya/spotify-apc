{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:50:32.519664Z",
     "start_time": "2018-07-01T15:50:32.513996Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Candidate Selection\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "\n",
    "import joblib\n",
    "\n",
    "path_to_df = 'gs://thesis_apc_bucket/df_data'\n",
    "\n",
    "df_tracks = spark.read.orc(path_to_df + '/df_tracks.orc')\n",
    "df_playlists = spark.read.orc(path_to_df + '/df_playlists.orc')\n",
    "df_playlists_metadata = spark.read.orc(path_to_df + '/df_playlists_metadata.orc')\n",
    "df_test_playlists = spark.read.orc(path_to_df + '/df_test_playlists.orc')\n",
    "df_test_metadata = spark.read.orc(path_to_df + '/df_test_metadata.orc')\n",
    "\n",
    "df_train = spark.read.orc(path_to_df + '/df_train.orc')\n",
    "df_val1 = spark.read.orc(path_to_df + '/df_val1.orc')\n",
    "df_val2 = spark.read.orc(path_to_df + '/df_val2.orc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pid list\n",
    "\n",
    "val1_pids = joblib.load(open('df_data/val1_pids.pkl', 'rb'))\n",
    "val2_pids = joblib.load(open('df_data/val2_pids.pkl', 'rb'))\n",
    "test_pids = joblib.load(open('df_data/test_pids.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "\n",
    "path_to_models = 'models2'\n",
    "\n",
    "model = joblib.load(open(path_to_models + '/lightfm_model.pkl', 'rb'))\n",
    "model_text = joblib.load(open(path_to_models + '/lightfm_model_text.pkl', 'rb'))\n",
    "user_features = joblib.load(open(path_to_models + '/user_features.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set config\n",
    "\n",
    "tid_max = df_tracks.agg({'tid': 'max'}).collect()[0]['max(tid)']\n",
    "\n",
    "config = {\n",
    "    'num_tracks': tid_max + 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up list known positives (dataframe version)\n",
    "\n",
    "df_user_seen = df_train.select(['pid', 'tid']).dropDuplicates()\n",
    "#                        .withColumnRenamed('pid', 'seen_pid').withColumnRenamed('tid', 'seen_tid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "997017"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config['num_tracks']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up functions for making batch predictions\n",
    "# Functions in this cell are taken from github.com/dmitryhd/lightfm\n",
    "\n",
    "import time\n",
    "from typing import Tuple, Union, Dict\n",
    "import multiprocessing as mp\n",
    "import logging\n",
    "import itertools\n",
    "\n",
    "# Inference functions --------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "_pool = None\n",
    "_item_chunks = {}\n",
    "CYTHON_DTYPE = np.float32\n",
    "ID_DTYPE = np.float32\n",
    "\n",
    "LightFM.logger = logging.getLogger('lightfm')\n",
    "\n",
    "def debug(self, *args, **kwargs):\n",
    "    self.logger.debug(*args, **kwargs)\n",
    "\n",
    "def info(self, *args, **kwargs):\n",
    "    self.logger.info(*args, **kwargs)\n",
    "\n",
    "def _construct_user_features(self, n_users, user_features):\n",
    "    if user_features is None:\n",
    "        user_features = sp.identity(n_users, dtype=CYTHON_DTYPE, format='csr')\n",
    "    else:\n",
    "        user_features = user_features.tocsr()\n",
    "\n",
    "    if n_users > user_features.shape[0]:\n",
    "        raise Exception('Number of user feature rows does not equal the number of users')\n",
    "\n",
    "    # If we already have embeddings, verify that\n",
    "    # we have them for all the supplied features\n",
    "    if self.user_embeddings is not None:\n",
    "        if not self.user_embeddings.shape[0] >= user_features.shape[1]:\n",
    "            raise ValueError(\n",
    "                'The user feature matrix specifies more features than there are estimated '\n",
    "                'feature embeddings: {} vs {}.'.format(self.user_embeddings.shape[0], user_features.shape[1])\n",
    "            )\n",
    "\n",
    "    user_features = self._to_cython_dtype(user_features)\n",
    "    return user_features\n",
    "\n",
    "def _construct_item_features(self, n_items: int, item_features: Union[sp.csr_matrix, None]) -> sp.csr_matrix:\n",
    "    # TODO: mb. merge with user features\n",
    "    if item_features is None:\n",
    "        item_features = sp.identity(n_items, dtype=CYTHON_DTYPE, format='csr')\n",
    "    else:\n",
    "        item_features = item_features.tocsr()\n",
    "\n",
    "    if n_items > item_features.shape[0]:\n",
    "        raise Exception('Number of item feature rows does not equal the number of items')\n",
    "\n",
    "    if self.item_embeddings is not None:\n",
    "        if not self.item_embeddings.shape[0] >= item_features.shape[1]:\n",
    "            raise ValueError(\n",
    "                'The item feature matrix specifies more features than there are estimated '\n",
    "                'feature embeddings: {} vs {}.'.format(self.item_embeddings.shape[0], item_features.shape[1])\n",
    "            )\n",
    "\n",
    "    item_features = self._to_cython_dtype(item_features)\n",
    "    return item_features\n",
    "\n",
    "LightFM.debug = debug\n",
    "LightFM.info = info\n",
    "LightFM._construct_user_features = _construct_user_features\n",
    "LightFM._construct_item_features = _construct_item_features\n",
    "\n",
    "def _check_setup():\n",
    "    if not (len(_user_repr)\n",
    "        and len(_user_repr_biases)\n",
    "        and len(_item_repr)\n",
    "        and len(_item_repr_biases)):\n",
    "\n",
    "        raise EnvironmentError('You must setup mode.batch_setup(item_ids) before using predict')\n",
    "\n",
    "def _batch_setup(model: LightFM,\n",
    "                 item_chunks: Dict[int, np.ndarray],\n",
    "                 item_features: Union[None, sp.csr_matrix]=None,\n",
    "                 user_features: Union[None, sp.csr_matrix]=None,\n",
    "                 n_process: int=1):\n",
    "\n",
    "    global _item_repr, _user_repr\n",
    "    global _item_repr_biases, _user_repr_biases\n",
    "    global _pool\n",
    "    global _item_chunks\n",
    "\n",
    "    if item_features is None:\n",
    "        n_items = len(model.item_biases)\n",
    "        item_features = sp.identity(n_items, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "    if user_features is None:\n",
    "        n_users = len(model.user_biases)\n",
    "        user_features = sp.identity(n_users, dtype=CYTHON_DTYPE, format='csr')\n",
    "\n",
    "    n_users = user_features.shape[0]\n",
    "    user_features = model._construct_user_features(n_users, user_features)\n",
    "    _user_repr, _user_repr_biases = _precompute_representation(\n",
    "        features=user_features,\n",
    "        feature_embeddings=model.user_embeddings,\n",
    "        feature_biases=model.user_biases,\n",
    "    )\n",
    "\n",
    "    n_items = item_features.shape[0]\n",
    "    item_features = model._construct_item_features(n_items, item_features)\n",
    "    _item_repr, _item_repr_biases = _precompute_representation(\n",
    "        features=item_features,\n",
    "        feature_embeddings=model.item_embeddings,\n",
    "        feature_biases=model.item_biases,\n",
    "    )\n",
    "    _item_repr = _item_repr.T\n",
    "    _item_chunks = item_chunks\n",
    "    _clean_pool()\n",
    "    # Pool creation should go last\n",
    "    if n_process > 1:\n",
    "        _pool = mp.Pool(processes=n_process)\n",
    "        \n",
    "def _clean_pool():\n",
    "    global _pool\n",
    "    if _pool is not None:\n",
    "        _pool.close()\n",
    "        _pool = None\n",
    "\n",
    "def _batch_cleanup():\n",
    "    global _item_ids, _item_repr, _user_repr, _pool, _item_chunks\n",
    "    _item_chunks = {}\n",
    "    _user_repr = np.array([])\n",
    "    _item_repr = np.ndarray([])\n",
    "    _clean_pool()\n",
    "    \n",
    "def _get_top_k_scores(scores: np.ndarray, k: int, item_ids: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :return: indices of items, top_k scores. All in score decreasing order.\n",
    "    \"\"\"\n",
    "\n",
    "    if k:\n",
    "        top_indices = np.argpartition(scores, -k)[-k:]\n",
    "        scores = scores[top_indices]\n",
    "        sorted_top_indices = np.argsort(-scores)\n",
    "        scores = scores[sorted_top_indices]\n",
    "        top_indices = top_indices[sorted_top_indices]\n",
    "    else:\n",
    "        top_indices = np.arange(len(scores))\n",
    "\n",
    "    if len(item_ids):\n",
    "        top_indices = np.array(item_ids)[top_indices]\n",
    "\n",
    "    return top_indices, scores\n",
    "    \n",
    "def _batch_predict_for_user(user_id: int, top_k: int=50, chunk_id: int=None, item_ids=None) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :return: indices of items, top_k scores. All in score decreasing order.\n",
    "    \"\"\"\n",
    "    # exclude biases from repr (last column of user_repr and last row of transposed item repr)\n",
    "    user_repr = _user_repr[int(user_id), :]\n",
    "\n",
    "    if chunk_id is not None:\n",
    "        item_ids = _item_chunks[chunk_id]\n",
    "    elif item_ids is None:\n",
    "        raise UserWarning('Supply item chunks at setup or item_ids in predict')\n",
    "\n",
    "    if item_ids is None or len(item_ids) == 0:\n",
    "        item_repr = _item_repr\n",
    "        item_repr_biases = _item_repr_biases\n",
    "    else:\n",
    "        item_repr = _item_repr[:, item_ids]\n",
    "        item_repr_biases = _item_repr_biases[item_ids]\n",
    "\n",
    "    scores = user_repr.dot(item_repr)\n",
    "    scores += _user_repr_biases[int(user_id)]\n",
    "    scores += item_repr_biases\n",
    "    return _get_top_k_scores(scores, k=top_k, item_ids=item_ids)\n",
    "\n",
    "def _precompute_representation(\n",
    "        features: sp.csr_matrix,\n",
    "        feature_embeddings: np.ndarray,\n",
    "        feature_biases: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    :param: features           csr_matrix         [n_objects, n_features]\n",
    "    :param: feature_embeddings np.ndarray(float)  [n_features, no_component]\n",
    "    :param: feature_biases     np.ndarray(float)  [n_features]\n",
    "    :return:\n",
    "    TODO:\n",
    "    tuple of\n",
    "    - representation    np.ndarray(float)  [n_objects, no_component+1]\n",
    "    - bias repr\n",
    "    \"\"\"\n",
    "\n",
    "    representation = features.dot(feature_embeddings)\n",
    "    representation_bias = features.dot(feature_biases)\n",
    "    return representation, representation_bias\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "# Main functions -------------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "def batch_setup(self,\n",
    "                item_chunks: Dict[int, np.ndarray],\n",
    "                item_features: Union[None, sp.csr_matrix]=None,\n",
    "                user_features: Union[None, sp.csr_matrix]=None,\n",
    "                n_process: int=1):\n",
    "#     from lightfm.inference import _batch_setup\n",
    "    self.n_process = n_process\n",
    "    _batch_setup(model=self, item_chunks=item_chunks, item_features=item_features, user_features=user_features, n_process=n_process)\n",
    "\n",
    "def batch_cleanup(self):\n",
    "#     from lightfm.inference import _batch_cleanup\n",
    "    _batch_cleanup()\n",
    "    \n",
    "def batch_predict(self,\n",
    "                  chunk_id: int,\n",
    "                  user_ids: Union[np.ndarray, list],\n",
    "                  top_k: int=50) -> Dict[int, Tuple[np.ndarray, np.ndarray]]:\n",
    "    \"\"\"\n",
    "    :return: dict by user id: item_indices, scores sorted by score\n",
    "    \"\"\"\n",
    "#     from lightfm.inference import _batch_predict_for_user, _check_setup, _pool, _item_chunks\n",
    "\n",
    "    self._check_initialized()\n",
    "    self.info('Batch predict: user_ids: {:,}, item_ids: {:,}'.format(len(user_ids), len(_item_chunks[chunk_id])))\n",
    "\n",
    "    recommendations = {}\n",
    "    if not isinstance(user_ids, np.ndarray):\n",
    "        user_ids = np.array(user_ids, dtype=ID_DTYPE)\n",
    "\n",
    "    _check_setup()\n",
    "    btime = time.time()\n",
    "\n",
    "    if self.n_process == 1:\n",
    "        self.debug('Start recommending: using single process')\n",
    "        for user_id in user_ids:\n",
    "            rec_ids, scores = _batch_predict_for_user(user_id=user_id, top_k=top_k, chunk_id=chunk_id)\n",
    "            recommendations[user_id] = rec_ids, scores\n",
    "    else:\n",
    "        self.debug('Start recommending: using multiprocessing')\n",
    "        recs_list = _pool.starmap(\n",
    "            _batch_predict_for_user,\n",
    "            zip(user_ids, itertools.repeat(top_k), itertools.repeat(chunk_id)),\n",
    "        )\n",
    "        recommendations = dict(zip(user_ids, recs_list))\n",
    "\n",
    "    elapsed_sec = time.time() - btime\n",
    "    elapsed_sec_by_user = elapsed_sec / len(user_ids)\n",
    "    self.info('Recommendations for chunk {:,} done in {:.3f}s. {:.4f} s by user'.format(\n",
    "        chunk_id, elapsed_sec, elapsed_sec_by_user,\n",
    "    ))\n",
    "    return recommendations\n",
    "\n",
    "# Add functions to LightFM class\n",
    "LightFM.batch_setup = batch_setup\n",
    "LightFM.batch_cleanup = batch_cleanup\n",
    "LightFM.batch_predict = batch_predict\n",
    "\n",
    "# ----------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pids = df_train.select('pid').rdd.map(lambda x: x[0]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:51:50.216305Z",
     "start_time": "2018-07-01T15:51:50.137860Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set up function to save candidates\n",
    "\n",
    "from pyspark.sql.functions import collect_list, isnan, when, count, col\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, BooleanType\n",
    "import pandas as pd\n",
    "\n",
    "def save_candidates(target_pids, df_size, file_name, df=None):\n",
    "    \n",
    "    # Generate list of target pid's\n",
    "    target_pids_text = list(set(target_pids).difference(train_pids))\n",
    "    target_pids_no_text = list(set(target_pids).difference(target_pids_text))\n",
    "    \n",
    "    # Make predictions based on model and get top 2000 candidates for each pid\n",
    "    print('Predicting for no text...')\n",
    "    model.batch_setup(\n",
    "        item_chunks={0: np.arange(config['num_tracks'])},\n",
    "        n_process=16, \n",
    "    )    \n",
    "    prediction_results = model.batch_predict(chunk_id=0, user_ids=target_pids_no_text, top_k=2000)\n",
    "    model.batch_cleanup()\n",
    "    \n",
    "    # Make predictions based on model_text and get top 10,000 candidates for each pid\n",
    "    print('Predicting for text...')\n",
    "    model_text.batch_setup(\n",
    "        item_chunks={0: np.arange(config['num_tracks'])},\n",
    "        n_process=16, \n",
    "        user_features=user_features,\n",
    "    )    \n",
    "    prediction_results_text = model_text.batch_predict(chunk_id=0, user_ids=target_pids_text, top_k=2000)\n",
    "    model_text.batch_cleanup()\n",
    "    \n",
    "    prediction_results.update(prediction_results_text)\n",
    "    \n",
    "    print('Constructing candidates dataframe...')\n",
    "    \n",
    "    if df is not None:\n",
    "        val_tracks = df.groupBy('pid').agg(collect_list('tid').alias('tid')).toPandas().set_index('pid').tid\n",
    "    \n",
    "    pids = []\n",
    "    tids = []\n",
    "    targets = []\n",
    "    \n",
    "    schema = StructType([])\n",
    "    if df is not None:\n",
    "        schema = StructType([\n",
    "                    StructField('pid', FloatType(), True),\n",
    "                    StructField('tid', IntegerType(), True),\n",
    "                    StructField('target', BooleanType(), True),\n",
    "                  ])\n",
    "    else:\n",
    "        schema = StructType([\n",
    "                    StructField('pid', FloatType(), True),\n",
    "                    StructField('tid', IntegerType(), True),\n",
    "                  ])\n",
    "    \n",
    "    for pid in target_pids:\n",
    "        size = df_size[pid]\n",
    "        l = max(size * 8, 700 + size)\n",
    "        pids += [pid] * l\n",
    "        tids += list(prediction_results[pid][0][:l])]\n",
    "        \n",
    "        if df is not None:\n",
    "            tracks_t = val_tracks[pid]\n",
    "            targets += [i in tracks_t for i in prediction_results[pid][0][:l]]\n",
    "    \n",
    "    # CHECKING RESULTS\n",
    "    print(\"l = \", l)\n",
    "    print(\"Length of pids: \", len(pids))\n",
    "    print(\"Length of tids: \", len(tids))\n",
    "\n",
    "    # Make candidates dataframe\n",
    "    # Pandas version\n",
    "    candidates = pd.DataFrame()\n",
    "    candidates['pid'] = pids\n",
    "    candidates['tid'] = tids\n",
    "    \n",
    "    # Append targets to candidates if df is supplied\n",
    "    if df is not None:\n",
    "        # Pandas version\n",
    "        candidates['target'] = targets\n",
    "\n",
    "    # Convert candidates to spark dataframe\n",
    "    df_candidates = spark.createDataFrame(candidates, schema)\n",
    "\n",
    "    # Remove candidates that are already in train (a.k.a. user_seen)\n",
    "    df_final_candidates = df_candidates.join(df_user_seen, ['pid', 'tid'], 'leftanti')\n",
    "\n",
    "    # Final check\n",
    "    if df is not None:\n",
    "        df_final_candidates.groupBy('target').count().show()\n",
    "\n",
    "    # Save final candidates to ORC file\n",
    "    df_final_candidates.write.mode('overwrite').orc(path_to_df + '/' + file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T16:04:21.433612Z",
     "start_time": "2018-07-01T15:52:04.807962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for no text...\n",
      "Predicting for text...\n",
      "Constructing candidates dataframe...\n",
      "l =  888\n",
      "Length of pids:  8225013\n",
      "Length of tids:  8225013\n",
      "+------+-------+\n",
      "|target|  count|\n",
      "+------+-------+\n",
      "|  true| 332139|\n",
      "| false|7655017|\n",
      "+------+-------+\n",
      "\n",
      "CPU times: user 30.8 s, sys: 3.29 s, total: 34.1 s\n",
      "Wall time: 18min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "val1_counts = df_val1.toPandas().pid.value_counts()\n",
    "\n",
    "save_candidates(\n",
    "    val1_pids.tolist(),\n",
    "    val1_counts,\n",
    "    'ii_candidate.orc',\n",
    "    df_val1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T16:16:48.444534Z",
     "start_time": "2018-07-01T16:04:21.435700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting for no text...\n",
      "Predicting for text...\n",
      "Constructing candidates dataframe...\n",
      "l =  888\n",
      "Length of pids:  8225013\n",
      "Length of tids:  8225013\n",
      "+------+-------+\n",
      "|target|  count|\n",
      "+------+-------+\n",
      "|  true| 328047|\n",
      "| false|7658526|\n",
      "+------+-------+\n",
      "\n",
      "CPU times: user 30.9 s, sys: 3.86 s, total: 34.8 s\n",
      "Wall time: 18min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "val2_counts = df_val2.toPandas().pid.value_counts()\n",
    "\n",
    "save_candidates(\n",
    "    val2_pids.tolist(),\n",
    "    val2_counts,\n",
    "    'iii_candidate.orc',\n",
    "    df_val2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add num_holdouts column to df_test_metadata\n",
    "\n",
    "df_test_metadata = df_test_metadata.withColumn('num_holdouts', df_test_metadata['num_tracks'] - df_test_metadata['num_samples'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T16:29:13.196247Z",
     "start_time": "2018-07-01T16:16:48.447871Z"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "test_counts = df_test_metadata.select(col('pid'), col('num_holdouts')).toPandas().set_index('pid').num_holdouts\n",
    "\n",
    "save_candidates(\n",
    "    test_pids.tolist(),\n",
    "    test_counts,\n",
    "    'test_candidate.orc'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
