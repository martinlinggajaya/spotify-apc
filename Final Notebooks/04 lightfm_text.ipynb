{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENBLAS_NUM_THREADS'] = '1'\n",
    "os.environ['OMP_NUM_THREADS'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from lightfm import LightFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"LightFM Text\") \\\n",
    "                    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataframes\n",
    "\n",
    "import joblib\n",
    "\n",
    "path_to_df = 'gs://thesis_spotify_apc_bucket/df_data'\n",
    "\n",
    "df_tracks = spark.read.orc(path_to_df + '/df_tracks.orc')\n",
    "df_playlists = spark.read.orc(path_to_df + '/df_playlists.orc')\n",
    "df_playlists_metadata = spark.read.orc(path_to_df + '/df_playlists_metadata.orc')\n",
    "df_test_playlists = spark.read.orc(path_to_df + '/df_test_playlists.orc')\n",
    "df_test_metadata = spark.read.orc(path_to_df + '/df_test_metadata.orc')\n",
    "\n",
    "df_train = spark.read.orc(path_to_df + '/df_train.orc')\n",
    "df_val = spark.read.orc(path_to_df + '/df_val1.orc')\n",
    "# val1_pids = joblib.load(path_to_df + '/val1_pids.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:30.943469Z",
     "start_time": "2018-07-01T15:19:30.912781Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup LightFM configuration\n",
    "\n",
    "pid_max = df_playlists_metadata.agg({'pid': 'max'}).collect()[0]['max(pid)']\n",
    "tid_max = df_tracks.agg({'tid': 'max'}).collect()[0]['max(tid)']\n",
    "\n",
    "config = {\n",
    "    'num_playlists': pid_max + 1,\n",
    "    'num_tracks': tid_max + 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_zeros is a dataframe of df_val.pid - df_train.pid.unique()\n",
    "\n",
    "df_zeros = df_val.join(df_train, on=['pid'], how='leftanti')\n",
    "# df_zeros.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_no_zeros is a dataframe of df_val.pid - df_zeros.pid\n",
    "\n",
    "df_no_zeros = df_val.join(df_zeros, on=['pid'], how='leftanti').limit(1000)\n",
    "# df_no_zeros.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare playlist names\n",
    "\n",
    "train_playlist_names = df_playlists_metadata.select(['pid', 'name'])\n",
    "playlist_names = train_playlist_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join playlist with names with a dataframe of all playlists\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "playlists_to_add = spark.range(config['num_playlists'])\n",
    "playlist_names = playlists_to_add.join(playlist_names, how='left', on= playlist_names.pid == playlists_to_add.id)\\\n",
    "                                 .select([col('id').alias('pid'), col('name')])\\\n",
    "                                 .fillna('')\n",
    "#                                  .withColumn('name', split(trim('name'), ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "playlist_names_pd = playlist_names.toPandas().set_index('pid').name\n",
    "# playlist_names_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:33:16.355381Z",
     "start_time": "2018-07-01T15:33:13.158171Z"
    }
   },
   "outputs": [],
   "source": [
    "# Vectorize using scikit-learn's CountVectorizser\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=2000)\n",
    "user_features = vectorizer.fit_transform(playlist_names_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:33:16.449249Z",
     "start_time": "2018-07-01T15:33:16.358317Z"
    }
   },
   "outputs": [],
   "source": [
    "user_features = sp.hstack([sp.eye(config['num_playlists']), user_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:19:31.867927Z",
     "start_time": "2018-07-01T15:19:30.946052Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setup sparse matrix for training\n",
    "\n",
    "train_row_indices = df_train.select('pid').rdd.flatMap(lambda x: x).collect()\n",
    "train_col_indices = df_train.select('tid').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "X_train = sp.coo_matrix(\n",
    "    (np.ones(df_train.count()), (train_row_indices, train_col_indices)),\n",
    "    shape=(config['num_playlists'], config['num_tracks'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sparse matrix for validation using df_zeros\n",
    "\n",
    "zeros_row_indices = df_zeros.select('pid').rdd.flatMap(lambda x: x).collect()\n",
    "zeros_col_indices = df_zeros.select('tid').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "X_zeros = sp.coo_matrix(\n",
    "    (np.ones(df_zeros.count()), (zeros_row_indices, zeros_col_indices)),\n",
    "    shape=(config['num_playlists'], config['num_tracks'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sparse matrix for validation using df_no_zeros\n",
    "\n",
    "no_zeros_row_indices = df_no_zeros.select('pid').rdd.flatMap(lambda x: x).collect()\n",
    "no_zeros_col_indices = df_no_zeros.select('tid').rdd.flatMap(lambda x: x).collect()\n",
    "\n",
    "X_no_zeros = sp.coo_matrix(\n",
    "    (np.ones(df_no_zeros.count()), (no_zeros_row_indices, no_zeros_col_indices)),\n",
    "    shape=(config['num_playlists'], config['num_tracks'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:33:16.454208Z",
     "start_time": "2018-07-01T15:33:16.451281Z"
    }
   },
   "outputs": [],
   "source": [
    "config['model_path'] = 'models/lightfm_model_text.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:33:17.365490Z",
     "start_time": "2018-07-01T15:33:17.362077Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare model\n",
    "\n",
    "model = LightFM(\n",
    "    no_components=200, \n",
    "    loss='warp', \n",
    "    learning_rate=0.03, \n",
    "    max_sampled=400, \n",
    "    random_state=1,\n",
    "    user_alpha=1e-05,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threads = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:45:17.381236Z",
     "start_time": "2018-07-01T15:33:17.366988Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "0.013668333 0.0014111366\n",
      "Epoch: 1\n",
      "0.013288334 0.0014912282\n",
      "Epoch: 2\n",
      "0.013033333 0.001460717\n",
      "Epoch: 3\n",
      "0.012835 0.001495042\n",
      "Epoch: 4\n",
      "0.012721666 0.0015141114\n",
      "Epoch: 5\n",
      "0.0126 0.0015026696\n",
      "Epoch: 6\n",
      "0.012578333 0.0014683448\n",
      "Epoch: 7\n",
      "0.012516666 0.0014149505\n",
      "Epoch: 8\n",
      "0.012379999 0.0014111366\n",
      "CPU times: user 1d 8h 27min 30s, sys: 56.6 s, total: 1d 8h 28min 26s\n",
      "Wall time: 4h 12min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train and save the best model\n",
    "\n",
    "from lightfm.evaluation import precision_at_k\n",
    "\n",
    "best_score = 0\n",
    "# epochs_without_change = 0\n",
    "\n",
    "for i in range(10):  # range(10)\n",
    "    \n",
    "    print('Epoch: {}'.format(i))\n",
    "    \n",
    "    model.fit_partial(X_train, epochs=5, num_threads=num_threads, user_features=user_features) # num_threads=50\n",
    "    \n",
    "    score_zeros = []\n",
    "    score_no_zeros = []\n",
    "    \n",
    "    # Calculate scores\n",
    "    precision_zeros = precision_at_k(model, \n",
    "                                     test_interactions=X_zeros, \n",
    "                                     train_interactions=X_train, \n",
    "                                     user_features=user_features,\n",
    "                                     k=600, check_intersections=False,\n",
    "                                     num_threads=num_threads)\n",
    "    score_zeros.append(precision_zeros)\n",
    "    precision_no_zeros = precision_at_k(model, \n",
    "                                        test_interactions=X_no_zeros, \n",
    "                                        train_interactions=X_train, \n",
    "                                        user_features=user_features,\n",
    "                                        k=600, check_intersections=False,\n",
    "                                        num_threads=num_threads)\n",
    "    score_no_zeros.append(precision_no_zeros)\n",
    "    \n",
    "    mean_score_zeros = np.mean(score_zeros)\n",
    "    mean_score_no_zeros = np.mean(score_no_zeros)\n",
    "    \n",
    "    print(mean_score_zeros, mean_score_no_zeros)\n",
    "    if mean_score_zeros > best_score:\n",
    "        joblib.dump(model, config['model_path'])\n",
    "        best_score = mean_score_zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:45:17.416330Z",
     "start_time": "2018-07-01T15:45:17.383320Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib.dump(user_features, open('models/user_features.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://models/lightfm_model.pkl [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://models/lightfm_model_text.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://models/lightfm_model_text_pd.pkl [Content-Type=application/octet-stream]...\n",
      "Copying file://models/user_features.pkl [Content-Type=application/octet-stream]...\n",
      "| [4 files][  8.6 GiB/  8.6 GiB]  204.1 MiB/s                                   \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://models/user_features_pd.pkl [Content-Type=application/octet-stream]...\n",
      "| [5 files][  8.6 GiB/  8.6 GiB]  191.8 MiB/s                                   \n",
      "Operation completed over 5 objects/8.6 GiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Upload file to GCS\n",
    "\n",
    "! gsutil cp models/* gs://thesis_spotify_apc_bucket/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-01T15:45:23.412688Z",
     "start_time": "2018-07-01T15:45:17.418274Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = joblib.load(open(config['model_path'], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
